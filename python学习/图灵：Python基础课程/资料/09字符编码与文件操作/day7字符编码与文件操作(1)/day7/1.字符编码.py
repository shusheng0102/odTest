'''
一 什么是字符编码?
计算机要想工作必须通电,即用‘电’驱使计算机干活,也就是说‘电’的特性决定了计算机的特性。
电的特性即高低电平(人类从逻辑上将二进制数1对应高电平,二进制数0对应低电平)
    简单来说就是一个灯泡亮一个灯泡不亮表示
        0代表灯泡不亮 (低电平)
        1代表灯泡亮  （高电平）
        那么2个灯泡可以表示的信息就有  00 01 10 11 4种 2的二次方
        那么3个灯泡可以表示的信息就有  000 001  100 010  110 101 011 111 8种  二的三次方
    结论：计算机只认识数字(二进制0101) 其他的数字10进制是通过二进制转换过来的
         很明显，我们平时在使用计算机时，用的都是人类能读懂的字符
        （用高级语言python编程的结果也无非是在文件内写了一堆字符），
        如何能让计算机读懂人类的字符？
        必须经过一个过程：
        #字符--------（翻译过程）------->数字
        #这个过程实际就是一个字符如何对应一个特定数字的标准，这个标准称之为字符编码
    字符编码的发展史与分类？
        计算机由美国人发明。
            英文编码
            ASCII   ascii用1个字节（8位二进制）代表一个二进制字符   01010100
                 8bit= 1Bytes
                1024Bytes=1KB
                1024KB=1MB
                1024MB=1GB
                1024GB=1TB
                1024TB=1PB
             最早的字符编码为ASCII，只规定了英文字母数字和一些特殊字符与数字的对应关系。
            一个字节  01010100
             所以，ASCII码最多只能表示 256 个符号。即：2**8 = 256，
             当然我们编程语言都用英文(python,java)没问题，ASCII够用，但是在处理数据时，
                    不同的国家有不同的语言，日本人会在自己的程序中加入日文，中国人会加入中文。
                    比如print('中文') python3自动设置好的  之前python2需要设置
                    ASCII无法表示中文
                        而要表示中文，单拿一个字节表表示一个汉子，是不可能的
                        中国文化博大精深
                        是不可能表达完的(连小学生都认识两千多个汉字)，
                        多个字节去表示
                        位数越多，代表的变化就多，这样，就可以尽可能多的表达出不同的汉字
            gb2312
                所以中国人规定了自己的标准gb2312编码，
                规定了包含中文在内的字符－>数字的对应关系。
            GBK的诞生   3个字节  01010100 01010100 01010100  2**24
                GB 2312的出现，基本满足了汉字的计算机处理需要，
                但对于人名、古汉语等方面出现的罕用字，GB 2312不能处理，
                这导致了后来GBK汉字字符集的出现。
            Shift_JIS
                日本人规定了自己的Shift_JIS编码
            Euc-kr
                韩国人规定了自己的Euc-kr编码
                （另外，韩国人说，
                要求世界统一用韩国编码，但世界人民没有搭理他们）
                原因 ：政治
            unicode的诞生 它是在内存里面的
                unicode常用2个字节（16位二进制）代表一个字符，生僻字需要用4个字节（32位二进制）
                这时候问题出现了，精通18国语言的 某某大海 谦虚的用8国语言写了一篇文档，
                那么这一篇文档，按照哪国的标准，都会出现乱码（因为此刻的各种标准都只是
                规定了自己国家的文字在内的字符跟数字的对应关系，如果单纯采用一种国家的编码格式，
                那么其余国家语言的文字在解析时就会出现乱码）
                所以迫切需要一个世界的标准（能包含全世界的语言）
                于是unicode应运而生（韩国人表示不服，然后没有什么卵用）
                    字母x，用unicode表示二进制0000 0000 0111 1000，所以unicode兼容ascii，也兼容万国
                    这时候乱码问题消失了，所有的文档我们都使用但是新问题出现了，如果我们的文档通篇都是英文，
                    你用unicode会比ascii耗费多一倍的空间，在存储和传输上十分的低效
            UTF-8的诞生  它是在硬盘里面的
                 本着节约的精神 又出现了把Unicode编码转化为“可变长编码”的UTF-8编码。
                UTF-8编码把一个Unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，
                    汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。
                    字符	    ASCII	         Unicode	                     UTF-8
                    A	    01000001	      00000000 01000001	             01000001
                    中	    没有	             11100100 01001110 00101101	     11100100 10111000 10101101
                    简单来说英文字母 UTF-8 使用的和 ASCII 对应关系 一样
                                而中文 UTF-8 使用 Unicode 对应关系
            unicode和UTF-8的关系
                1、在存入磁盘时，需要将unicode转成一种更为精准的格式，
                utf-8:全称Unicode Transformation Format，将数据量控制到最精简
                2、在读入内存时，需要将utf-8转成unicode
                所以我们需要明确：内存中用unicode是为了兼容万国软件，
                即便是硬盘中有各国编码编写的软件，unicode也有相对应的映射关系，
                但在现在的开发中，程序员普遍使用utf-8编码了，
                估计在将来的某一天等所有老的软件都淘汰掉了情况下，
                就可以变成：内存unicode<->硬盘utf-8的形式了。
'''










